{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>pip install grpc_cache\n</code></pre> <p>or</p> <pre><code>poetry add grpc_cache\n</code></pre>"},{"location":"asyncio/","title":"AsyncGRPCCache","text":"<p>A caching utility for gRPC methods using Redis as a backend.</p> <p>This class provides decorators to cache gRPC responses based on specific message fields.</p> Example <pre><code>from grpc_cache.asyncio import grpc_cache\nfrom grpc_cache.backends.redis import RedisAsyncBackend\nfrom redis.asyncio import Redis\n\nfrom my_proto.messages_pb2 import MyRequest, MyResponse, MyServicer\n\n\nredis = Redis.from_url(\"redis://localhost:6379/0\")\nsetup_grpc_cache(backend=RedisAsyncBackend(redis=redis), ex=timedelta(minutes=1))\n\n\nclass MyService(MyServicer):\n    @grpc_cache(fields_for_key=[\"field1\", \"field2\"], ex=timedelta(minutes=5))\n    async def MyMethod(self, request: MyRequest, context) -&gt; MyResponse:\n        # Perform some logic\n        return MyResponse(result=\"Hello World\")\n</code></pre> Source code in <code>grpc_cache/asyncio.py</code> <pre><code>class AsyncGRPCCache:\n    \"\"\"\n    A caching utility for gRPC methods using Redis as a backend.\n\n    This class provides decorators to cache gRPC responses based on specific message fields.\n\n    Example:\n        ```python\n        from grpc_cache.asyncio import grpc_cache\n        from grpc_cache.backends.redis import RedisAsyncBackend\n        from redis.asyncio import Redis\n\n        from my_proto.messages_pb2 import MyRequest, MyResponse, MyServicer\n\n\n        redis = Redis.from_url(\"redis://localhost:6379/0\")\n        setup_grpc_cache(backend=RedisAsyncBackend(redis=redis), ex=timedelta(minutes=1))\n\n\n        class MyService(MyServicer):\n            @grpc_cache(fields_for_key=[\"field1\", \"field2\"], ex=timedelta(minutes=5))\n            async def MyMethod(self, request: MyRequest, context) -&gt; MyResponse:\n                # Perform some logic\n                return MyResponse(result=\"Hello World\")\n        ```\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._backend: AsyncBackend | None = None\n        self.ex: int | timedelta | None = None\n\n    def __call__(\n        self,\n        fields_for_key: list[str] | None = None,\n        ex: int | timedelta | None = None,\n        protobuf: Message = None,\n        prefix: str = None,\n    ) -&gt; Callable[[gRPCAsyncMethod], gRPCAsyncMethod]:\n        \"\"\"\n        Decorator to enable caching for a gRPC method.\n\n        Args:\n            fields_for_key: List of field names to construct the cache key.\n            ex: Expiration time for the cache, in seconds or as a timedelta.\n            protobuf: Protobuf message type for serialization (optional if return type is annotated).\n            prefix: Optional prefix for cache keys.\n\n        Returns:\n            Decorator function.\n\n        Example:\n            ```python\n            from grpc_cache.asyncio import grpc_cache\n\n            from my_proto.messages_pb2 import MyRequest, MyResponse, MyServicer\n\n\n            class MyService(MyServicer):\n                @grpc_cache(fields_for_key=[\"field1\", \"field2\"], ex=timedelta(minutes=5))\n                async def MyMethod(self, request: MyRequest, context) -&gt; MyResponse:\n                    # Perform some logic\n                    return MyResponse(result=\"Hello World\")\n\n                async def AnotherMethod(self, request: MyRequest, context) -&gt; MyResponse:\n                    await self.MyMethod.clear(request.field1, request.field2)  # clear cache for MyMethod\n                    return MyResponse(result=\"Hello World\")\n            ```\n        \"\"\"\n\n        if fields_for_key is None:\n            fields_for_key = []\n\n        ex = ex or self.ex\n\n        if not isinstance(ex, int | timedelta):\n            raise TypeError(\"ex must be an int or timedelta.\")\n\n        def inner(func: gRPCAsyncMethod) -&gt; gRPCAsyncMethod:\n            nonlocal protobuf, ex, prefix\n\n            prefix = prefix or func.__qualname__\n            func_signature = signature(func)\n\n            if len(func_signature.parameters) != 3:\n                raise ValueError(\"gRPC method signature must have 3 arguments.\")\n\n            protobuf = protobuf or func_signature.return_annotation\n\n            if not protobuf or protobuf is func_signature.empty:\n                raise ValueError(\"You must specify the protobuf argument or a return type annotation.\")\n\n            async def clear_cache(*args):\n                \"\"\"\n                Callback for clearing cache while calling another gRPC method.\n\n                Args:\n                    *args: values for cache key\n                \"\"\"\n                cache_key = \":\".join([prefix, *args])\n                try:\n                    await self._backend.delete(pattern=cache_key)\n                except RedisError as e:\n                    logger.warning(f\"Redis is unavailable: {e}\")\n                except Exception as e:\n                    logger.warning(f\"Unexpected error: {e}\")\n\n            func.clear = clear_cache\n\n            @wraps(wrapped=func)\n            async def wrapper(servicer, message, context) -&gt; Message:\n                \"\"\"\n                Wrapper function to handle caching logic.\n                \"\"\"\n\n                # Construct the cache key\n                key_parts = [prefix] + [f\"{getattr(message, field)}\" for field in fields_for_key]\n                cache_key = \":\".join(key_parts)\n\n                try:\n                    cached_response = await self._backend.get(key=cache_key)\n                    if cached_response:\n                        return protobuf.FromString(cached_response)\n                except (TypeError, RedisError, AttributeError) as e:\n                    if isinstance(e, RedisError | AttributeError):\n                        logger.warning(f\"Redis is unavailable: {e}\")\n\n                # Execute the original function and cache the result\n                response = await func(servicer, message, context)\n                cached_response = response.SerializeToString()\n\n                try:\n                    await self._backend.set(key=cache_key, value=cached_response, ex=ex)\n                except (RedisError, AttributeError) as e:\n                    logger.warning(f\"Failed to cache response: {e}\")\n\n                return response\n\n            return wrapper\n\n        return inner\n\n    def setup(self, backend: AsyncBackend, ex: int | timedelta) -&gt; None:\n        \"\"\"\n        Configures the gRPC cache.\n\n        Args:\n            ex: Default expiration time for the cache, in seconds or as a timedelta.\n            backend: Backend storage.\n\n        Example:\n            ```python\n            from grpc_cache.asyncio import setup_grpc_cache\n            from grpc_cache.backends.redis import RedisAsyncBackend\n            from redis.asyncio import Redis\n\n            redis = Redis.from_url(\"redis://localhost:6379/0\")\n            setup_grpc_cache(backend=RedisAsyncBackend(redis=redis), ex=timedelta(minutes=1))\n            ```\n        \"\"\"\n        self._backend = backend\n        self.ex = ex\n</code></pre>"},{"location":"asyncio/#grpc_cache.asyncio.AsyncGRPCCache.__call__","title":"<code>__call__(fields_for_key=None, ex=None, protobuf=None, prefix=None)</code>","text":"<p>Decorator to enable caching for a gRPC method.</p> <p>Parameters:</p> Name Type Description Default <code>fields_for_key</code> <code>list[str] | None</code> <p>List of field names to construct the cache key.</p> <code>None</code> <code>ex</code> <code>int | timedelta | None</code> <p>Expiration time for the cache, in seconds or as a timedelta.</p> <code>None</code> <code>protobuf</code> <code>Message</code> <p>Protobuf message type for serialization (optional if return type is annotated).</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Optional prefix for cache keys.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[[gRPCAsyncMethod], gRPCAsyncMethod]</code> <p>Decorator function.</p> Example <pre><code>from grpc_cache.asyncio import grpc_cache\n\nfrom my_proto.messages_pb2 import MyRequest, MyResponse, MyServicer\n\n\nclass MyService(MyServicer):\n    @grpc_cache(fields_for_key=[\"field1\", \"field2\"], ex=timedelta(minutes=5))\n    async def MyMethod(self, request: MyRequest, context) -&gt; MyResponse:\n        # Perform some logic\n        return MyResponse(result=\"Hello World\")\n\n    async def AnotherMethod(self, request: MyRequest, context) -&gt; MyResponse:\n        await self.MyMethod.clear(request.field1, request.field2)  # clear cache for MyMethod\n        return MyResponse(result=\"Hello World\")\n</code></pre> Source code in <code>grpc_cache/asyncio.py</code> <pre><code>def __call__(\n    self,\n    fields_for_key: list[str] | None = None,\n    ex: int | timedelta | None = None,\n    protobuf: Message = None,\n    prefix: str = None,\n) -&gt; Callable[[gRPCAsyncMethod], gRPCAsyncMethod]:\n    \"\"\"\n    Decorator to enable caching for a gRPC method.\n\n    Args:\n        fields_for_key: List of field names to construct the cache key.\n        ex: Expiration time for the cache, in seconds or as a timedelta.\n        protobuf: Protobuf message type for serialization (optional if return type is annotated).\n        prefix: Optional prefix for cache keys.\n\n    Returns:\n        Decorator function.\n\n    Example:\n        ```python\n        from grpc_cache.asyncio import grpc_cache\n\n        from my_proto.messages_pb2 import MyRequest, MyResponse, MyServicer\n\n\n        class MyService(MyServicer):\n            @grpc_cache(fields_for_key=[\"field1\", \"field2\"], ex=timedelta(minutes=5))\n            async def MyMethod(self, request: MyRequest, context) -&gt; MyResponse:\n                # Perform some logic\n                return MyResponse(result=\"Hello World\")\n\n            async def AnotherMethod(self, request: MyRequest, context) -&gt; MyResponse:\n                await self.MyMethod.clear(request.field1, request.field2)  # clear cache for MyMethod\n                return MyResponse(result=\"Hello World\")\n        ```\n    \"\"\"\n\n    if fields_for_key is None:\n        fields_for_key = []\n\n    ex = ex or self.ex\n\n    if not isinstance(ex, int | timedelta):\n        raise TypeError(\"ex must be an int or timedelta.\")\n\n    def inner(func: gRPCAsyncMethod) -&gt; gRPCAsyncMethod:\n        nonlocal protobuf, ex, prefix\n\n        prefix = prefix or func.__qualname__\n        func_signature = signature(func)\n\n        if len(func_signature.parameters) != 3:\n            raise ValueError(\"gRPC method signature must have 3 arguments.\")\n\n        protobuf = protobuf or func_signature.return_annotation\n\n        if not protobuf or protobuf is func_signature.empty:\n            raise ValueError(\"You must specify the protobuf argument or a return type annotation.\")\n\n        async def clear_cache(*args):\n            \"\"\"\n            Callback for clearing cache while calling another gRPC method.\n\n            Args:\n                *args: values for cache key\n            \"\"\"\n            cache_key = \":\".join([prefix, *args])\n            try:\n                await self._backend.delete(pattern=cache_key)\n            except RedisError as e:\n                logger.warning(f\"Redis is unavailable: {e}\")\n            except Exception as e:\n                logger.warning(f\"Unexpected error: {e}\")\n\n        func.clear = clear_cache\n\n        @wraps(wrapped=func)\n        async def wrapper(servicer, message, context) -&gt; Message:\n            \"\"\"\n            Wrapper function to handle caching logic.\n            \"\"\"\n\n            # Construct the cache key\n            key_parts = [prefix] + [f\"{getattr(message, field)}\" for field in fields_for_key]\n            cache_key = \":\".join(key_parts)\n\n            try:\n                cached_response = await self._backend.get(key=cache_key)\n                if cached_response:\n                    return protobuf.FromString(cached_response)\n            except (TypeError, RedisError, AttributeError) as e:\n                if isinstance(e, RedisError | AttributeError):\n                    logger.warning(f\"Redis is unavailable: {e}\")\n\n            # Execute the original function and cache the result\n            response = await func(servicer, message, context)\n            cached_response = response.SerializeToString()\n\n            try:\n                await self._backend.set(key=cache_key, value=cached_response, ex=ex)\n            except (RedisError, AttributeError) as e:\n                logger.warning(f\"Failed to cache response: {e}\")\n\n            return response\n\n        return wrapper\n\n    return inner\n</code></pre>"},{"location":"asyncio/#grpc_cache.asyncio.AsyncGRPCCache.setup","title":"<code>setup(backend, ex)</code>","text":"<p>Configures the gRPC cache.</p> <p>Parameters:</p> Name Type Description Default <code>ex</code> <code>int | timedelta</code> <p>Default expiration time for the cache, in seconds or as a timedelta.</p> required <code>backend</code> <code>AsyncBackend</code> <p>Backend storage.</p> required Example <pre><code>from grpc_cache.asyncio import setup_grpc_cache\nfrom grpc_cache.backends.redis import RedisAsyncBackend\nfrom redis.asyncio import Redis\n\nredis = Redis.from_url(\"redis://localhost:6379/0\")\nsetup_grpc_cache(backend=RedisAsyncBackend(redis=redis), ex=timedelta(minutes=1))\n</code></pre> Source code in <code>grpc_cache/asyncio.py</code> <pre><code>def setup(self, backend: AsyncBackend, ex: int | timedelta) -&gt; None:\n    \"\"\"\n    Configures the gRPC cache.\n\n    Args:\n        ex: Default expiration time for the cache, in seconds or as a timedelta.\n        backend: Backend storage.\n\n    Example:\n        ```python\n        from grpc_cache.asyncio import setup_grpc_cache\n        from grpc_cache.backends.redis import RedisAsyncBackend\n        from redis.asyncio import Redis\n\n        redis = Redis.from_url(\"redis://localhost:6379/0\")\n        setup_grpc_cache(backend=RedisAsyncBackend(redis=redis), ex=timedelta(minutes=1))\n        ```\n    \"\"\"\n    self._backend = backend\n    self.ex = ex\n</code></pre>"},{"location":"cache/","title":"GRPCCache","text":"<p>A caching utility for gRPC methods using Redis as a backend.</p> <p>This class provides decorators to cache gRPC responses based on specific message fields.</p> Example <pre><code>from grpc_cache import grpc_cache, setup_grpc_cache\nfrom grpc_cache.backends.redis import RedisSyncBackend\nfrom redis import Redis\n\nfrom my_proto.messages_pb2 import MyRequest, MyResponse, MyServicer\n\n\nredis = Redis.from_url(\"redis://localhost:6379/0\")\nsetup_grpc_cache(backend=RedisSyncBackend(redis=redis), ex=timedelta(minutes=1))\n\n\nclass MyService(MyServicer):\n    @grpc_cache(fields_for_key=[\"field1\", \"field2\"], ex=timedelta(minutes=5))\n    def MyMethod(self, request: MyRequest, context) -&gt; MyResponse:\n        # Perform some logic\n        return MyResponse(result=\"Hello World\")\n</code></pre> Source code in <code>grpc_cache/cache.py</code> <pre><code>class GRPCCache:\n    \"\"\"\n    A caching utility for gRPC methods using Redis as a backend.\n\n    This class provides decorators to cache gRPC responses based on specific message fields.\n\n    Example:\n        ```python\n        from grpc_cache import grpc_cache, setup_grpc_cache\n        from grpc_cache.backends.redis import RedisSyncBackend\n        from redis import Redis\n\n        from my_proto.messages_pb2 import MyRequest, MyResponse, MyServicer\n\n\n        redis = Redis.from_url(\"redis://localhost:6379/0\")\n        setup_grpc_cache(backend=RedisSyncBackend(redis=redis), ex=timedelta(minutes=1))\n\n\n        class MyService(MyServicer):\n            @grpc_cache(fields_for_key=[\"field1\", \"field2\"], ex=timedelta(minutes=5))\n            def MyMethod(self, request: MyRequest, context) -&gt; MyResponse:\n                # Perform some logic\n                return MyResponse(result=\"Hello World\")\n        ```\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._backend: SyncBackend | None = None\n        self.ex: int | timedelta | None = None\n\n    def __call__(\n        self,\n        fields_for_key: list[str] | None = None,\n        ex: int | timedelta | None = None,\n        protobuf: Message = None,\n        prefix: str = None,\n    ) -&gt; Callable[[gRPCSyncMethod], gRPCSyncMethod]:\n        \"\"\"\n        Decorator to enable caching for a gRPC method.\n\n        Args:\n            fields_for_key: List of field names to construct the cache key.\n            ex: Expiration time for the cache, in seconds or as a timedelta.\n            protobuf: Protobuf message type for serialization (optional if return type is annotated).\n            prefix: Optional prefix for cache keys.\n\n        Returns:\n            Decorator function.\n\n        Example:\n            ```python\n            from grpc_cache import grpc_cache\n\n            from my_proto.messages_pb2 import MyRequest, MyResponse, MyServicer\n\n\n            class MyService(MyServicer):\n                @grpc_cache(fields_for_key=[\"field1\", \"field2\"], ex=timedelta(minutes=5))\n                def MyMethod(self, request: MyRequest, context) -&gt; MyResponse:\n                    # Perform some logic\n                    return MyResponse(result=\"Hello World\")\n\n                def AnotherMethod(self, request: MyRequest, context) -&gt; MyResponse:\n                    self.MyMethod.clear(request.field1, request.field2)  # clear cache for MyMethod\n                    return MyResponse(result=\"Hello World\")\n            ```\n        \"\"\"\n\n        if fields_for_key is None:\n            fields_for_key = []\n\n        ex = ex or self.ex\n\n        if not isinstance(ex, int | timedelta):\n            raise TypeError(\"ex must be an int or timedelta.\")\n\n        def inner(func: gRPCSyncMethod) -&gt; gRPCSyncMethod:\n            nonlocal protobuf, ex, prefix\n\n            prefix = prefix or func.__qualname__\n            func_signature = signature(func)\n\n            if len(func_signature.parameters) != 3:\n                raise ValueError(\"gRPC method signature must have 3 arguments.\")\n\n            protobuf = protobuf or func_signature.return_annotation\n\n            if not protobuf or protobuf is func_signature.empty:\n                raise ValueError(\"You must specify the protobuf argument or a return type annotation.\")\n\n            def clear_cache(*args):\n                \"\"\"\n                Callback for clearing cache while calling another gRPC method.\n\n                Args:\n                    *args: values for cache key\n                \"\"\"\n                cache_key = \":\".join([prefix, *[f\"{v}\" for v in args]])\n                try:\n                    self._backend.delete(pattern=cache_key)\n                except RedisError as e:\n                    logger.warning(f\"Redis is unavailable: {e}\")\n                except Exception as e:\n                    logger.warning(f\"Unexpected error: {e}\")\n\n            func.clear = clear_cache\n\n            @wraps(wrapped=func)\n            def wrapper(servicer, message, context) -&gt; Message:\n                \"\"\"\n                Wrapper function to handle caching logic.\n                \"\"\"\n\n                # Construct the cache key\n                key_parts = [prefix] + [f\"{getattr(message, field)}\" for field in fields_for_key]\n                cache_key = \":\".join(key_parts)\n\n                try:\n                    cached_response = self._backend.get(key=cache_key)\n                    if cached_response:\n                        return protobuf.FromString(cached_response)\n                except (TypeError, RedisError, AttributeError) as e:\n                    if isinstance(e, RedisError | AttributeError):\n                        logger.warning(f\"Redis is unavailable: {e}\")\n\n                # Execute the original function and cache the result\n                response = func(servicer, message, context)\n                cached_response = response.SerializeToString()\n\n                try:\n                    self._backend.set(key=cache_key, value=cached_response, ex=ex)\n                except (RedisError, AttributeError) as e:\n                    logger.warning(f\"Failed to cache response: {e}\")\n\n                return response\n\n            return wrapper\n\n        return inner\n\n    def setup(self, backend: SyncBackend, ex: int | timedelta) -&gt; None:\n        \"\"\"\n        Configures the gRPC cache.\n\n        Args:\n            ex: Default expiration time for the cache, in seconds or as a timedelta.\n            backend: Backend storage.\n\n        Example:\n            ```python\n            from grpc_cache import setup_grpc_cache\n            from grpc_cache.backends.redis import RedisSyncBackend\n            from redis import Redis\n\n            redis = Redis.from_url(\"redis://localhost:6379/0\")\n            setup_grpc_cache(backend=RedisSyncBackend(redis=redis), ex=timedelta(minutes=1))\n            ```\n        \"\"\"\n        self._backend = backend\n        self.ex = ex\n</code></pre>"},{"location":"cache/#grpc_cache.cache.GRPCCache.__call__","title":"<code>__call__(fields_for_key=None, ex=None, protobuf=None, prefix=None)</code>","text":"<p>Decorator to enable caching for a gRPC method.</p> <p>Parameters:</p> Name Type Description Default <code>fields_for_key</code> <code>list[str] | None</code> <p>List of field names to construct the cache key.</p> <code>None</code> <code>ex</code> <code>int | timedelta | None</code> <p>Expiration time for the cache, in seconds or as a timedelta.</p> <code>None</code> <code>protobuf</code> <code>Message</code> <p>Protobuf message type for serialization (optional if return type is annotated).</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Optional prefix for cache keys.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[[gRPCSyncMethod], gRPCSyncMethod]</code> <p>Decorator function.</p> Example <pre><code>from grpc_cache import grpc_cache\n\nfrom my_proto.messages_pb2 import MyRequest, MyResponse, MyServicer\n\n\nclass MyService(MyServicer):\n    @grpc_cache(fields_for_key=[\"field1\", \"field2\"], ex=timedelta(minutes=5))\n    def MyMethod(self, request: MyRequest, context) -&gt; MyResponse:\n        # Perform some logic\n        return MyResponse(result=\"Hello World\")\n\n    def AnotherMethod(self, request: MyRequest, context) -&gt; MyResponse:\n        self.MyMethod.clear(request.field1, request.field2)  # clear cache for MyMethod\n        return MyResponse(result=\"Hello World\")\n</code></pre> Source code in <code>grpc_cache/cache.py</code> <pre><code>def __call__(\n    self,\n    fields_for_key: list[str] | None = None,\n    ex: int | timedelta | None = None,\n    protobuf: Message = None,\n    prefix: str = None,\n) -&gt; Callable[[gRPCSyncMethod], gRPCSyncMethod]:\n    \"\"\"\n    Decorator to enable caching for a gRPC method.\n\n    Args:\n        fields_for_key: List of field names to construct the cache key.\n        ex: Expiration time for the cache, in seconds or as a timedelta.\n        protobuf: Protobuf message type for serialization (optional if return type is annotated).\n        prefix: Optional prefix for cache keys.\n\n    Returns:\n        Decorator function.\n\n    Example:\n        ```python\n        from grpc_cache import grpc_cache\n\n        from my_proto.messages_pb2 import MyRequest, MyResponse, MyServicer\n\n\n        class MyService(MyServicer):\n            @grpc_cache(fields_for_key=[\"field1\", \"field2\"], ex=timedelta(minutes=5))\n            def MyMethod(self, request: MyRequest, context) -&gt; MyResponse:\n                # Perform some logic\n                return MyResponse(result=\"Hello World\")\n\n            def AnotherMethod(self, request: MyRequest, context) -&gt; MyResponse:\n                self.MyMethod.clear(request.field1, request.field2)  # clear cache for MyMethod\n                return MyResponse(result=\"Hello World\")\n        ```\n    \"\"\"\n\n    if fields_for_key is None:\n        fields_for_key = []\n\n    ex = ex or self.ex\n\n    if not isinstance(ex, int | timedelta):\n        raise TypeError(\"ex must be an int or timedelta.\")\n\n    def inner(func: gRPCSyncMethod) -&gt; gRPCSyncMethod:\n        nonlocal protobuf, ex, prefix\n\n        prefix = prefix or func.__qualname__\n        func_signature = signature(func)\n\n        if len(func_signature.parameters) != 3:\n            raise ValueError(\"gRPC method signature must have 3 arguments.\")\n\n        protobuf = protobuf or func_signature.return_annotation\n\n        if not protobuf or protobuf is func_signature.empty:\n            raise ValueError(\"You must specify the protobuf argument or a return type annotation.\")\n\n        def clear_cache(*args):\n            \"\"\"\n            Callback for clearing cache while calling another gRPC method.\n\n            Args:\n                *args: values for cache key\n            \"\"\"\n            cache_key = \":\".join([prefix, *[f\"{v}\" for v in args]])\n            try:\n                self._backend.delete(pattern=cache_key)\n            except RedisError as e:\n                logger.warning(f\"Redis is unavailable: {e}\")\n            except Exception as e:\n                logger.warning(f\"Unexpected error: {e}\")\n\n        func.clear = clear_cache\n\n        @wraps(wrapped=func)\n        def wrapper(servicer, message, context) -&gt; Message:\n            \"\"\"\n            Wrapper function to handle caching logic.\n            \"\"\"\n\n            # Construct the cache key\n            key_parts = [prefix] + [f\"{getattr(message, field)}\" for field in fields_for_key]\n            cache_key = \":\".join(key_parts)\n\n            try:\n                cached_response = self._backend.get(key=cache_key)\n                if cached_response:\n                    return protobuf.FromString(cached_response)\n            except (TypeError, RedisError, AttributeError) as e:\n                if isinstance(e, RedisError | AttributeError):\n                    logger.warning(f\"Redis is unavailable: {e}\")\n\n            # Execute the original function and cache the result\n            response = func(servicer, message, context)\n            cached_response = response.SerializeToString()\n\n            try:\n                self._backend.set(key=cache_key, value=cached_response, ex=ex)\n            except (RedisError, AttributeError) as e:\n                logger.warning(f\"Failed to cache response: {e}\")\n\n            return response\n\n        return wrapper\n\n    return inner\n</code></pre>"},{"location":"cache/#grpc_cache.cache.GRPCCache.setup","title":"<code>setup(backend, ex)</code>","text":"<p>Configures the gRPC cache.</p> <p>Parameters:</p> Name Type Description Default <code>ex</code> <code>int | timedelta</code> <p>Default expiration time for the cache, in seconds or as a timedelta.</p> required <code>backend</code> <code>SyncBackend</code> <p>Backend storage.</p> required Example <pre><code>from grpc_cache import setup_grpc_cache\nfrom grpc_cache.backends.redis import RedisSyncBackend\nfrom redis import Redis\n\nredis = Redis.from_url(\"redis://localhost:6379/0\")\nsetup_grpc_cache(backend=RedisSyncBackend(redis=redis), ex=timedelta(minutes=1))\n</code></pre> Source code in <code>grpc_cache/cache.py</code> <pre><code>def setup(self, backend: SyncBackend, ex: int | timedelta) -&gt; None:\n    \"\"\"\n    Configures the gRPC cache.\n\n    Args:\n        ex: Default expiration time for the cache, in seconds or as a timedelta.\n        backend: Backend storage.\n\n    Example:\n        ```python\n        from grpc_cache import setup_grpc_cache\n        from grpc_cache.backends.redis import RedisSyncBackend\n        from redis import Redis\n\n        redis = Redis.from_url(\"redis://localhost:6379/0\")\n        setup_grpc_cache(backend=RedisSyncBackend(redis=redis), ex=timedelta(minutes=1))\n        ```\n    \"\"\"\n    self._backend = backend\n    self.ex = ex\n</code></pre>"},{"location":"clear/","title":"Clear cache","text":"<p>To delete the cache of a method when calling a linked method, you must call the <code>clear</code> method.</p> <p>Examples:</p> <p>Sync  <pre><code>@grpc_cache(fields_for_key=[\"user_id\", \"project_id\"])\ndef MyMethod(self, request, context) -&gt; Response:\n    # Some logic\n    return Response(...)\n\ndef AnotherMethod(self, request, context) -&gt; AnotherResponse:\n    self.MeMethod.clear(request.user_id, request.project_id)\n    return AnotherResponse(...)\n</code></pre></p> <p>Async <pre><code>@grpc_cache(fields_for_key=[\"user_id\", \"project_id\"])\nasync def MyMethod(self, request, context) -&gt; Response:\n    # Some logic\n    return Response(...)\n\nasync def AnotherMethod(self, request, context) -&gt; AnotherResponse:\n    await self.MeMethod.clear(request.user_id, request.project_id)\n    return AnotherResponse(...)\n</code></pre></p> <p>You can use wildcard to delete multiple cache entries.</p> <pre><code>@grpc_cache(fields_for_key=[\"user_id\", \"page\"])\nasync def List(self, request, context) -&gt; Response:\n    # Some logic\n    return Response(...)\n\nasync def AnotherMethod(self, request, context) -&gt; AnotherResponse:\n    await self.List.clear(request.user_id, \"*\")\n    return AnotherResponse(...)\n</code></pre>"}]}